#!/usr/bin/env python3
"""
Web scraping module for fetching trending hashtags and keywords from various sources
"""

import requests
from bs4 import BeautifulSoup
import re
import os
import time
import random
from typing import List, Dict, Tuple
from urllib.parse import urljoin
import json

class TrendsScraper:
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)

    def scrape_instagram_hashtags(self, keywords: List[str]) -> List[Tuple[str, float]]:
        """Scrape trending hashtags from Instagram-related sources"""
        trending_hashtags = []
        
        # Simulate trending hashtags based on keywords (since Instagram API requires auth)
        # In real implementation, you'd use Instagram Basic Display API or third-party services
        base_trends = [
            "ë§›ìŠ¤íƒ€ê·¸ë¨", "foodstagram", "ì¹´í˜ìŠ¤íƒ€ê·¸ë¨", "dessertgram", "Seoulë§›ì§‘",
            "í™í”Œë ˆì´ìŠ¤", "ë°ì¼ë¦¬ì¹´í˜", "ì„œìš¸ì¹´í˜", "ì¸ìŠ¤íƒ€í•«í”Œ", "ê°ì„±ì¹´í˜"
        ]
        
        for keyword in keywords:
            # Generate contextual hashtags
            trending_hashtags.extend([
                (f"#{keyword}ìŠ¤íƒ€ê·¸ë¨", 0.8),
                (f"#{keyword}ì¶”ì²œ", 0.7),
                (f"#{keyword}ë§›ì§‘", 0.9),
                (f"#{keyword}ë°ì¼ë¦¬", 0.6)
            ])
        
        # Add base trending hashtags
        for hashtag in base_trends:
            trending_hashtags.append((f"#{hashtag}", random.uniform(0.5, 0.9)))
            
        return trending_hashtags[:15]

    def scrape_naver_blog_trends(self) -> List[Tuple[str, float]]:
        """Scrape trending keywords from Naver Blog using real API"""
        try:
            # Use Naver Search API
            client_id = os.getenv('NAVER_CLIENT_ID')
            client_secret = os.getenv('NAVER_CLIENT_SECRET')
            
            if not all([client_id, client_secret]):
                print("âš ï¸  Naver API credentials not configured")
                return self._fallback_naver_trends()
            
            headers = {
                'X-Naver-Client-Id': client_id,
                'X-Naver-Client-Secret': client_secret,
                'User-Agent': self.headers['User-Agent']
            }
            
            trending_keywords = []
            
            # Search for trending food/cafe posts
            search_terms = ["ì„œìš¸ë§›ì§‘", "ì¹´í˜ì¶”ì²œ", "ë””ì €íŠ¸ë§›ì§‘", "ë¹™ìˆ˜ì¶”ì²œ", "í•«í”Œë ˆì´ìŠ¤"]
            
            for term in search_terms:
                url = "https://openapi.naver.com/v1/search/blog.json"
                params = {
                    'query': term,
                    'display': 20,
                    'sort': 'date'  # Most recent posts
                }
                
                response = self.session.get(url, headers=headers, params=params)
                
                if response.status_code == 200:
                    data = response.json()
                    
                    # Extract keywords from blog titles and descriptions
                    for item in data.get('items', []):
                        title = item.get('title', '')
                        description = item.get('description', '')
                        
                        # Clean HTML tags
                        import re
                        title = re.sub('<[^<]+?>', '', title)
                        description = re.sub('<[^<]+?>', '', description)
                        
                        # Extract relevant keywords
                        text = f"{title} {description}".lower()
                        
                        # Score based on how recent and relevant the post is
                        score = 0.7 + (len(data['items']) - data['items'].index(item)) * 0.01
                        
                        # Add location-based trends
                        if any(loc in text for loc in ['ì—°ë‚¨', 'ì„±ìˆ˜', 'í™ëŒ€', 'ê°•ë‚¨']):
                            location_kw = next(loc for loc in ['ì—°ë‚¨', 'ì„±ìˆ˜', 'í™ëŒ€', 'ê°•ë‚¨'] if loc in text)
                            trending_keywords.append((f"{location_kw}ë§›ì§‘", min(score + 0.1, 1.0)))
                        
                        # Add content-based trends  
                        if any(food in text for food in ['ë¹™ìˆ˜', 'ì¹´í˜', 'ë””ì €íŠ¸']):
                            food_kw = next(food for food in ['ë¹™ìˆ˜', 'ì¹´í˜', 'ë””ì €íŠ¸'] if food in text)
                            trending_keywords.append((f"{food_kw}ì¶”ì²œ", score))
                
                time.sleep(0.1)  # Rate limiting
            
            return trending_keywords if trending_keywords else self._fallback_naver_trends()
            
        except Exception as e:
            print(f"Error scraping Naver trends: {e}")
            return self._fallback_naver_trends()
    
    def _fallback_naver_trends(self) -> List[Tuple[str, float]]:
        """Fallback data when Naver API is unavailable"""
        return [
            ("ì„œìš¸í•«í”Œ", 0.85), ("ê°ì„±ì¹´í˜", 0.82), ("ì¸ìƒìƒ·ë§›ì§‘", 0.78),
            ("MZì¶”ì²œ", 0.75), ("ìˆ¨ì€ë§›ì§‘", 0.73), ("ê°€ì„±ë¹„ì¹´í˜", 0.70),
            ("ë°ì´íŠ¸ì½”ìŠ¤", 0.68), ("ì£¼ë§ë‚˜ë“¤ì´", 0.65)
        ]

    def scrape_google_trends_korea(self, keywords: List[str]) -> List[Tuple[str, float]]:
        """Fetch trending searches related to Korean food/cafe topics"""
        # This would integrate with Google Trends API in real implementation
        # For now, simulating trending terms
        korean_food_trends = [
            ("ì—°ë‚¨ë™ì¹´í˜", 0.88),
            ("ì„±ìˆ˜ë™ë§›ì§‘", 0.85),
            ("í™ëŒ€ë””ì €íŠ¸", 0.82),
            ("ê°•ë‚¨ì¹´í˜", 0.78),
            ("ì´íƒœì›ë§›ì§‘", 0.75),
            ("ë§ì›ë™ì¹´í˜", 0.72),
            ("ì„œì´Œë§›ì§‘", 0.70),
            ("ì‹ ì‚¬ë™ì¹´í˜", 0.68)
        ]
        
        return korean_food_trends

    def scrape_youtube_trending_titles(self) -> List[str]:
        """Scrape trending video titles for hook inspiration"""
        # This would use YouTube Data API in real implementation
        trending_patterns = [
            "ì´ê±° ëª¨ë¥´ë©´ ì†í•´",
            "ì§„ì§œ ë§›ìˆëŠ” ê³³ ì°¾ì•˜ë‹¤",
            "ì„œìš¸ ìˆ¨ì€ ë§›ì§‘ ëŒ€ê³µê°œ",
            "MZì„¸ëŒ€ê°€ ì—´ê´‘í•˜ëŠ”",
            "ì¸ìƒ ì¹´í˜ ë°œê²¬",
            "ê°€ì„±ë¹„ ëíŒì™•",
            "í˜„ì§€ì¸ë§Œ ì•„ëŠ” ë¹„ë°€",
            "ì¤„ ì„œì„œ ë¨¹ì„ ê°€ì¹˜ ìˆë‚˜",
            "ì†”ì§ í›„ê¸°ë§Œ ëª¨ìŒ",
            "ì´ ì¡°í•© ë¯¸ì³¤ë‹¤"
        ]
        
        return trending_patterns

    def get_all_trends(self, keywords: List[str]) -> Dict[str, List[Tuple[str, float]]]:
        """Fetch all trending data from various sources"""
        trends = {
            'instagram_hashtags': self.scrape_instagram_hashtags(keywords),
            'naver_trends': self.scrape_naver_blog_trends(),
            'google_trends': self.scrape_google_trends_korea(keywords),
            'youtube_patterns': [(pattern, 0.8) for pattern in self.scrape_youtube_trending_titles()]
        }
        
        return trends

def integrate_web_trends_to_system():
    """Integration function to fetch and merge web trends with existing system"""
    scraper = TrendsScraper()
    
    # Get base keywords from existing system
    from trends_fetchers import get_final_keywords
    base_keywords = get_final_keywords()
    
    # Fetch web trends
    web_trends = scraper.get_all_trends(base_keywords)
    
    # Merge and rank all trends
    all_trends = []
    for source, trends in web_trends.items():
        for trend, score in trends:
            all_trends.append((trend, score, source))
    
    # Sort by score and return top trends
    all_trends.sort(key=lambda x: x[1], reverse=True)
    return all_trends[:30]

if __name__ == "__main__":
    trends = integrate_web_trends_to_system()
    print("ğŸ”¥ Top Trending Terms:")
    for i, (trend, score, source) in enumerate(trends[:10], 1):
        print(f"{i:2d}. {trend:<20} ({score:.2f}) from {source}")
